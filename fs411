#!/usr/bin/python3

# fs411
# See argparse section below for details on input and output.
# This allows a lot of flexibility in extracting information from FreeSurfer runs.

# Use others' code to make our lives easier
import sys  # To get command-line arguments
import argparse  # A framework for parsing command-line arguments
import os  # For digging through directories and files
import re  # Regular expression support
import datetime  # To handle dates and times
import csv  # To write the final csv mrs file easily
from collections import OrderedDict  # for named dictionaries of volumes and such
from datetime import date
from datetime import timedelta
import time
import glob  # for searching for original spgr files, fullname unknown

# Local file containing dictionaries of FreeSurfer variables
from mrs_dicts import *
from fs_fxns import *

##------------------------------------------------------------------------------
##-- Define constants and globals for later use
##------------------------------------------------------------------------------
TS_Format = "%a %b %d %H:%M:%S %Z %Y"

subjectid = ""
ts_begin = datetime.datetime(1975, 3, 11, 0, 0, 0)
ts_end = ts_begin
StartedOver = ' '
left_hcv = ''
right_hcv = ''
hcvfile = 0


##------------------------------------------------------------------------------
##-- Define functions for later use
##------------------------------------------------------------------------------


# Sanity check... Do things look like we expect?
def input_ok(mypath):
    if os.path.isdir(mypath):
        partial = False
        full = True
        for fk, fv in fs_file("all").items():
            if os.path.isfile(mypath + fv):
                partial = True
            else:
                full = False
        if full:
            # Only if the directory exists and has all expected files should we continue.
            return True
        elif partial:
            # This is actually OK for retrieving error status, but returning True means
            # it is now necessary to make every function robust to missing files.
            # print("I found \"{0}\". It has incomplete FreeSurfer data.".format(mypath))
            return True
        else:
            print("I found \"{argdir}\", but it does not appear to contain freesurfer data.".format(argdir=mypath))
            return False
    else:
        print("I cannot find the directory, \"{argdir}\".".format(argdir=mypath))
        return False
    print("This is a bug in the \"input_ok()\" function. I am not detecting files appropriately.")
    return False


# Extract the date the original MRI was collected
#    This function is embarrassingly confined to GENOA data on my one server.
#    I need the function and don't see a better way to handle it, though.
#    All other usage will get "NA" for their dates.
def get_scan_date():
    retval = "NA"
    potential_files = glob.glob("/mri/gmbi.*.original/{0}/{0}*spgr.img".format(subjectid))
    if len(potential_files) != 1:
        return retval
    if os.path.isfile(potential_files[0]):
        # There is only one matching file, and it exists, so parse its name.
        reg_mridate = re.compile(r'.*_(?P<Y>\d\d\d\d)(?P<M>\d\d)(?P<D>\d\d)_spgr.img')
        mat_date = reg_mridate.match(potential_files[0])
        if mat_date:
            retval = "{Y}-{M}-{D}".format(Y=mat_date.group('Y'), M=mat_date.group('M'), D=mat_date.group('D'))
        else:
            print("{0} is not the expected filename pattern.".format(potential_files[0]))
    return (retval)


# Write fields and values to csv file
def outputcsv(mynames, myvalues, myfile):
    file_is_new = not os.path.isfile(myfile)
    with open(myfile, 'a') as csvfile:
        mywriter = csv.writer(csvfile, delimiter=",", quotechar="\"", quoting=csv.QUOTE_MINIMAL)
        if file_is_new:
            mywriter.writerow(mynames)
        mywriter.writerow(myvalues)


# Save out the freesurfer data in tabular format for a single fs file
def write_fsfile(outfilename, fstype, which_version="6.0.0"):
    myname = outfilename
    if args.filetype == "all":
        if myname[-4:] != ".csv":
            myname = myname + ".csv"
        if "mrs" in myname:
            myname = myname.replace("mrs", fstype)
        else:
            myname = outfilename[:-4] + '.' + fstype + outfilename[-4:]
    mydata = []
    rownames = []
    rowdata = []
    for n, d in get_meta_dict(subjectid, get_fs_time(subjectroot, "short", "end")).items():
        mydata.append((n, d))

    if fstype == 'aseg':
        aseg_dict = get_fs_data(subjectroot, fstype)
        for k, v in aseg_dict.items():
            try:
                mydata.append((k, aseg_dict[n]))
            except KeyError:
                # print("   keyerror, can't find {0} in {1}".format(k, fstype))
                mydata.append((k, "NA"))
    elif fstype == 'wmparc':
        wmparc_dict = get_fs_data(subjectroot, fstype)
        for n in get_wmparc_ordered_list(which_version):
            try:
                mydata.append((n, wmparc_dict[n]))
            except KeyError:
                # print("   keyerror, can't find {0} in {1}".format(n, fstype))
                mydata.append((n, "NA"))
    elif fstype == 'aparc':
        aparc_dict = OrderedDict([(k + '_L', v) for k, v in get_fs_data(subjectroot, 'aparc1l').items()])
        aparc_dict.update(OrderedDict([(k + '_R', v) for k, v in get_fs_data(subjectroot, 'aparc1r').items()]))
        for n in get_aparc_ordered_list(which_version):
            n_L = "{0}_L".format(n)
            n_R = "{0}_R".format(n)
            try:
                mydata.append((n_L, aparc_dict[n_L]))
            except KeyError:
                #print("   keyerror, can't find {0} in {1}".format(n_L, fstype))
                mydata.append((n_L, "NA"))
            try:
                mydata.append((n_R, aparc_dict[n_R]))
            except KeyError:
                #print("   keyerror, can't find {0} in {1}".format(n_R, fstype))
                mydata.append((n_R, "NA"))

    for i in mydata:
        rownames.append(i[0])
        rowdata.append(i[1])

    print("Writing raw {ft} data for {sid} to {fp}".format(ft=fstype, sid=subjectid, fp=myname))
    outputcsv(rownames, rowdata, myname)


# Order the variables and their labels for an mrs-formatted file
def write_mrsfile(wholedict, csvmrsfile):
    myname = csvmrsfile
    if args.filetype == "all":
        # with "all", we are generating four uniquely named files from a single input file.
        if myname[-4:] != ".csv":
            myname = myname + ".csv"
        if "mrs" not in myname:
            myname = myname[:-4] + '.mrs.csv'
    rowNames = []
    rowData = []
    for n, d in get_mrs_meta_dict(subjectid, get_scan_date(), get_fs_time(subjectroot, "short", "end")).items():
        rowNames.append(n)
        rowData.append(d)
    for n, d in get_mrs_dict(get_fsversion(subjectroot, "short")).items():
        # each key-value pair looks like 'mrs#':'Name'
        # append the identifier (key) to the beginning of the mrs list
        rowNames.append(n)
        # and find the appropriate data value to match it
        if wholedict.get(d, "FAIL") != "FAIL":
            # Successful lookup of mrs number from FreeSurfer description
            rowData.append(wholedict.get(d, "FAIL"))
        else:
            if d == "Scandate_Month":
                rowData.append(get_scan_date()[5:7])
            elif d == "Scandate_Day":
                rowData.append(get_scan_date()[8:10])
            elif d == "Scandate_Year":
                rowData.append(get_scan_date()[0:4])
            elif d == "Scandate_Time":
                rowData.append(get_scan_date()[11:])
            elif d == "Analysisdate_Month":
                rowData.append(get_fs_time(subjectroot, "short", "end")[5:7])
            elif d == "Analysisdate_Day":
                rowData.append(get_fs_time(subjectroot, "short", "end")[8:10])
            elif d == "Analysisdate_Year":
                rowData.append(get_fs_time(subjectroot, "short", "end")[0:4])
            elif d == "Analysisdate_Time":
                rowData.append(get_fs_time(subjectroot, "short", "end")[11:])
            elif d == "ThalamusProper_T":
                # This exception is necessary to match the tweaked mrs variable names
                lval = float(wholedict.get('Left-Thalamus-Proper', "0.0"))  # Match at Left-***
                rval = float(wholedict.get('Right-Thalamus-Proper', "0.0"))  # Match at Right-***
                rowData.append("{:0.2f}".format(lval + rval))
            elif d == "Vetrical_T":
                # This exception adds up all ventricles and stores them under the mrs mis-spelling
                ventricles = (float(wholedict.get('Left-Lateral-Ventricle', "0.0")) +
                              float(wholedict.get('Left-Inf-Lat-Vent', "0.0")) +
                              float(wholedict.get('3rd-Ventricle', "0.0")) +
                              float(wholedict.get('4th-Ventricle', "0.0")) +
                              float(wholedict.get('Right-Lateral-Ventricle', "0.0")) +
                              float(wholedict.get('Right-Inf-Lat-Vent', "0.0")) +
                              float(wholedict.get('5th-Ventricle', "0.0")))
                rowData.append("{:0.2f}".format(ventricles))
            elif d[-2:] == "_T":
                # We have a "total" field, so we need to find the left and right fields to add for it
                if wholedict.get(d[:-2] + '_L', "FAIL") == "FAIL":
                    if wholedict.get('Left-' + d[:-2], "FAIL") == "FAIL":
                        # print("--== ERROR: {4}-{0}: {1} but no {2} or {3}. Setting it to 0.0".format(n, d, d[:-2] + '_L', 'Left-' + d[:-2], subjectid))
                        lval = 0.0  # No match, actual failure
                    else:
                        lval = float(wholedict.get('Left-' + d[:-2], "0.0"))  # Match at Left-***
                else:
                    lval = float(wholedict.get(d[:-2] + '_L', "0.0"))  # Match at ***_L
                if wholedict.get(d[:-2] + '_R', "FAIL") == "FAIL":
                    if wholedict.get('Right-' + d[:-2], "FAIL") == "FAIL":
                        # print("--== ERROR: {4}-{0}: {1} but no {2} or {3}. Setting it to 0.0".format(n, d, d[:-2] + '_R', 'Right-' + d[:-2], subjectid))
                        rval = 0.0  # No match, actual failure
                    else:
                        rval = float(wholedict.get('Right-' + d[:-2], "0.0"))  # Match at Right-***
                else:
                    rval = float(wholedict.get(d[:-2] + '_R', "0.0"))  # Match at ***_R
                rowData.append("{:0.2f}".format(lval + rval))
            elif n[-3:] == "MRS":
                rowData.append("NA")
            else:
                rowData.append("0.00")
    print("Writing standard mrs data for {sid} to {fp}".format(sid=subjectid, fp=myname))
    outputcsv(rowNames, rowData, myname)


# Print data differently depending on sparsity and verbosity
def output_item(the_item):
    if args.sparse:
        print(the_item)
    else:
        print("{sid} : {d}".format(sid=subjectid, d=the_item))


##------------------------------------------------------------------------------
##-- Define expected command-line arguments
##------------------------------------------------------------------------------


# Parse command-line arguments
argparser = argparse.ArgumentParser(description='Dig for information from FreeSurfer output')
argparser.add_argument('rootfolder', help='Provide a subject\'s root FreeSurfer output folder.')
argparser.add_argument('-s', '--sparse', action='store_true', help='Avoid printing the ID, keep it sparse.')
argparser.add_argument('-v', '--version_short', action='store_true', help='Output the dot version of FreeSurfer used.')
argparser.add_argument('-V', '--version_long', action='store_true', help='Output the full version of FreeSurfer used.')
argparser.add_argument('-t', '--time_short', action='store_true',
                       help='Output the total elapsed time of the whole run.')
argparser.add_argument('-T', '--time_long', action='store_true', help='Output the individual timings of each step.')
argparser.add_argument('-u', '--username', action='store_true', help='Output the user account running freesurfer.')
argparser.add_argument('-m', '--machine', action='store_true', help='Output the host on which this subject was run.')
argparser.add_argument('-c', '--completion', action='store_true', help='Output success or failure of the job.')
argparser.add_argument('-d', '--completedate', action='store_true',
                       help='Output the date FreeSurfer completed its processing.')
argparser.add_argument('-D', '--scandate', action='store_true',
                       help='Only works for GENOA naming of files, return date of MRI.')
argparser.add_argument('-i', '--item', help='Output the item specified, looked up by FreeSurfer StructName.')
argparser.add_argument('--filetype', help='aseg,aparc,wmparc,mrs or all , used with --outfile')
argparser.add_argument('--outfile', help='Generate a csv file with the name specified, default is filetype=all.')

args = argparser.parse_args()

subjectroot = os.path.abspath(args.rootfolder)

# Do we have a legitimate set of freesurfer data to work with?
if not input_ok(subjectroot):
    # Errors will be printed from input_ok
    sys.exit()


##------------------------------------------------------------------------------
##-- Finally, with functions and arguments ready, do our thing...
##------------------------------------------------------------------------------


# Start by determining the subject ID
reg_id = re.compile(r'.*(?P<sid>[A-Za-z][0-9]{6})')
mat_id = reg_id.match(subjectroot)
if mat_id:
    subjectid = mat_id.group('sid')
else:
    print("I can't determine a subject's ID from '{}'.".format(subjectroot))
    sys.exit()

# Deal with versioning
if args.version_short:
    output_item(get_fsversion(subjectroot, verbosity="short"))
elif args.version_long:
    output_item(get_fsversion(subjectroot, verbosity="long"))

# Deal with elapsed times
if args.time_short:
    output_item(get_fs_time(subjectroot, verbosity="short", timetype="elapsed", sparsity=False))
elif args.time_long:
    output_item(get_fs_time(subjectroot, verbosity="long", timetype="elapsed", sparsity=False))

# Determine the completion status
if args.completion:
    if os.path.isfile(subjectroot + fs_file("err")):
        if args.sparse:
            print("error   ")
        else:
            f = open(subjectroot + fs_file("err"))
            lastline = ""
            for line in f:
                lastline = line
            f.close()
            print("{} : Error in '{}'".format(subjectid, lastline))
    if os.path.isfile(subjectroot + fs_file("done")):
        output_item("complete")

# Determine the user or hostname
if args.username:
    output_item(get_fs_username(subjectroot))

# Determine the machine name that ran FreeSurfer
if args.machine:
    output_item(get_fs_hostname(subjectroot))

# Determine the date FreeSurfer completed
if args.completedate:
    output_item(get_fs_time(subjectroot, timetype='end'))

# Determine the date the MRI was done
if args.scandate:
    output_item(get_scan_date())

# Look up item in FreeSurfer files
if args.item:
    if args.sparse:
        print(get_fs_item(subjectroot, which_item=args.item))
    else:
        print("{sid} : {structname} = {structvalue}".format(
            sid=subjectid, structname=args.item,
            structvalue=get_fs_item(subjectroot, which_item=args.item)
        ))

# Generate whole csvs with bunches of data
if args.outfile:
    if args.filetype == "aseg" or args.filetype == "all":
        write_fsfile(args.outfile, 'aseg', get_fsversion(subjectroot, verbosity="short"))
    if args.filetype == "wmparc" or args.filetype == "all":
        write_fsfile(args.outfile, 'wmparc', get_fsversion(subjectroot, verbosity="short"))
    if args.filetype == "aparc" or args.filetype == "all":
        write_fsfile(args.outfile, 'aparc', get_fsversion(subjectroot, verbosity="short"))
    if args.filetype == "mrs" or args.filetype == "all":
        dict_whole = get_fs_data(subjectroot, 'aseg')
        dict_whole.update(get_fs_data(subjectroot, 'wmparc'))
        dict_whole.update(OrderedDict([(k + '_L', v) for k, v in get_fs_data(subjectroot, 'aparc1l').items()]))
        dict_whole.update(OrderedDict([(k + '_R', v) for k, v in get_fs_data(subjectroot, 'aparc1r').items()]))
        write_mrsfile(dict_whole, args.outfile)

