#!/usr/bin/python3

## Input:
#    a full path to a folder containing Freesurfer output
#    This usu. looks something like "/home/mike/Brains/Rochester/R000001"
#

## Output:
#    Depending on the arguments provided at presentation, data derived
#    from the Freesurfer process, see arguments for details.
#    This is for extracting subject data like brain volumes, and for
#    metadata concerning the freesurfer process that generated them.

## We expect to find certain folders and files within any of these structures.
## Differences in filecounts here can indicate failure at different places
## through the pipeline.
#    ./bem             ?
#    ./label           ~69 files (.ctab, .annot, .label) containing labels for regions within images
#    ./mri             ~34 files, 24 output images with .mgz extensions
#         /orig        The mgz version of the input image
#         /transforms  Talairach transformations of the original
#    ./scripts         ~12 log files, useful for determining environment and commands issued
#    ./src             ?
#    ./stats           18 .stats files, quantitative results for volumes, areas, etc.
#    ./surf            ~70 files
#    ./tmp             ?
#    ./touch           Records of some commands in the pipeline
#    ./trash           ?


## Use others' code to make our lives easier
import sys  # To get command-line arguments
import argparse  # A framework for parsing command-line arguments
import os  # For digging through directories and files
import re  # Regular expression support
import datetime  # To handle dates and times
import csv  # To write the final csv mrs file easily
from collections import OrderedDict  # for named dictionaries of volumes and such
from datetime import date
from datetime import timedelta
from dateutil import parser
from dateutil.tz import gettz
import time
import glob  # for searching for original spgr files, fullname unknown

# Local file containing dictionaries of FreeSurfer variables
from mrs_dicts import *

##------------------------------------------------------------------------------
##-- Define constants and globals for later use
##------------------------------------------------------------------------------
TS_Format = "%a %b %d %H:%M:%S %Z %Y"

## Define any globals
neededfiles = {'log': '/scripts/recon-all.log',
               'stamp': '/scripts/build-stamp.txt',
               'cmd': '/scripts/recon-all.cmd',
               'aseg': '/stats/aseg.stats',
               'wmparc': '/stats/wmparc.stats',
               'aparc1l': '/stats/lh.aparc.stats',
               'aparc1r': '/stats/rh.aparc.stats',
               'aparc2l': '/stats/lh.aparc.a2009s.stats',
               'aparc2r': '/stats/rh.aparc.a2009s.stats',
               'aparc3l': '/stats/lh.aparc.DKTatlas40.stats',
               'aparc3r': '/stats/rh.aparc.DKTatlas40.stats'}
optionfiles = {'err': '/scripts/recon-all.error',
               'done': '/scripts/recon-all.done'}

subjectid = ""
ts_begin = datetime.datetime(1975, 3, 11, 0, 0, 0)
ts_end = ts_begin
tzinfos = {"CST": gettz("America/Chicago"), "CDT": gettz("America/Chicago"),
           "EST": gettz("America/New_York"), "EDT": gettz("America/New_York")}
StartedOver = ' '
left_hcv = ''
right_hcv = ''
hcvfile = 0


##------------------------------------------------------------------------------
##-- Define functions for later use
##------------------------------------------------------------------------------


##-- Sanity check... Do things look like we expect?
def input_ok(mypath):
    if os.path.isdir(mypath):
        partial = False
        full = True
        for fd, fv in neededfiles.items():
            if os.path.isfile(mypath + fv):
                partial = True
            else:
                full = False
        if full:
            # Only if the directory exists and has all expected files should we continue.
            return True
        elif partial:
            # This is actually OK for retrieving error status, but returning True means
            # it is now necessary to make every function robust to missing files.
            # print("I found \"{argdir}\". It has some freesurfer data, but not everything expected.".format(argdir=mypath))
            return True
        else:
            print("I found \"{argdir}\", but it does not appear to contain freesurfer data.".format(argdir=mypath))
            return False
    else:
        print("I cannot find the directory, \"{argdir}\".".format(argdir=mypath))
        return False
    print(
        "Damn! This is a bug in the \"input_ok()\" function. Execution should never have reached this point. I am not detecting files appropriately.")
    return False


## end input_ok function


##-- Extract the version information
def get_fsversion(verbosity="short", sparsity=False):
    stampfile = subjectroot + neededfiles['stamp']
    version_string = ""
    if not os.path.isfile(stampfile):
        return ("N/A")
    f = open(stampfile)
    for line in f:
        if '\n' == line[-1]:
            line = line[:-1]
        version_string = line
    f.close()
    if verbosity == "short":
        short_version_string=version_string[version_string.find("pub-v") + len("pub-v"):]
        return (short_version_string[:5])
    # else verbosity must be long
    return (version_string)


# / end get_fsversion() function


##-- Extract the elapsed time
def get_fstime(verbosity="short", timetype="elapsed", sparsity=False):
    cmdfile = subjectroot + neededfiles['cmd']
    if not os.path.isfile(cmdfile):
        return ("N/A")
    timestrings = []
    # tfstring="%a %b %d %X %Z %Y"
    first_time = datetime.datetime.now()
    last_time = datetime.datetime.now()
    this_time = datetime.datetime.now()
    reg_tstamp = re.compile(r'^#@# (?P<task>.*) (?P<stmp>\w{3}\s+\w+\s+\d+\s+\d\d:\d\d:\d\d\s+\w{3}\s+\d{4})')
    f = open(cmdfile)
    n = 0
    for line in f:
        mat_tstamp = reg_tstamp.match(line)
        if mat_tstamp:
            if n == 0:
                # first_time = datetime.datetime.strptime(mat_tstamp.group('stmp'), tfstring)
                first_time = parser.parse(mat_tstamp.group('stmp'), tzinfos=tzinfos)
                last_time = first_time
            n += 1
            # this_time = datetime.datetime.strptime(mat_tstamp.group('stmp'), tfstring)
            this_time = parser.parse(mat_tstamp.group('stmp'), tzinfos=tzinfos)
            td_small = this_time - last_time
            td_large = this_time - first_time
            if verbosity == "long":
                if sparsity:
                    timestrings.append("{:2} : {:5.0f}\n".format(n, td_small.total_seconds()))
                else:
                    timestrings.append("{:2} : {:28} : {} ({:5.0f}, {:5.0f})\n".format(n, mat_tstamp.group('task'),
                                                                                       mat_tstamp.group('stmp'),
                                                                                       td_small.total_seconds(),
                                                                                       td_large.total_seconds()))
            last_time = this_time
    f.close()
    if verbosity == "short":
        if sparsity:
            timestrings.append("{:5.0f}".format(td_large.total_seconds()))
        else:
            timestrings.append("{:5.0f} seconds ({:2.1f} hrs)".format(td_large.total_seconds(), td_large.total_seconds() / 3600.0))
    if (timetype == "elapsed"):
        return (''.join(timestrings))
    if (timetype == "begin"):
        return (first_time.strftime("%Y-%m-%dT%H:%M:%S%z"))
    if (timetype == "end"):
        return (last_time.strftime("%Y-%m-%dT%H:%M:%S%z"))


## / end get_fselapsed() function


##-- Extract the hostname on which freesurfer was run
def get_fshostname(verbosity, sparsity=False):
    retval = ""
    if os.path.isfile(subjectroot + optionfiles["done"]):
        reg_machine = re.compile(r'.*HOST (?P<machine>\w*).*')
        f = open(subjectroot + optionfiles["done"])
        for line in f:
            mat_machine = reg_machine.match(line)
            if mat_machine:
                retval = mat_machine.group('machine')
        f.close()
    return (retval)


## / end get_fshostname() function


##-- Extract the username under which freesurfer was run
def get_fsusername(verbosity, sparsity=False):
    retval = ""
    if os.path.isfile(subjectroot + optionfiles["done"]):
        reg_username = re.compile(r'.*USER (?P<username>\w*).*')
        f = open(subjectroot + optionfiles["done"])
        for line in f:
            mat_username = reg_username.match(line)
            if mat_username:
                retval = mat_username.group('username')
        f.close()
    return (retval)


## / end get_fsusername() function


##-- Extract the date the original MRI was collected
#    This function is embarrassingly confined to GENOA data on one machine.
#    All other usage will get "NA" for their dates.
def get_scandate(sparsity=False):
    retval = "NA"
    potential_files = glob.glob("/mri/gmbi.*.original/{0}/{0}*spgr.img".format(subjectid))
    if len(potential_files) != 1:
        return retval
    if os.path.isfile(potential_files[0]):
        # There is only one matching file, and it exists, so parse its name.
        reg_mridate = re.compile(r'.*_(?P<Y>\d\d\d\d)(?P<M>\d\d)(?P<D>\d\d)_spgr.img')
        mat_date = reg_mridate.match(potential_files[0])
        if mat_date:
            retval = "{Y}-{M}-{D}".format(Y=mat_date.group('Y'), M=mat_date.group('M'), D=mat_date.group('D'))
        else:
            print("{0} is not the expected filename pattern.".format(potential_files[0]))
    return (retval)


## / end get_fsusername() function


##-- Extract a volume or area
def get_fsvolume(whichnum="", sparsity=False):
    retval = ""
    # Merge dictionaries
    dict_whole = get_fsdata('aseg')
    dict_whole.update(get_fsdata('wmparc'))
    dict_whole.update(OrderedDict([(k + '_L', v) for k, v in get_fsdata('aparc1l').items()]))
    dict_whole.update(OrderedDict([(k + '_R', v) for k, v in get_fsdata('aparc1r').items()]))
    try:
        retval = dict_whole[whichnum]
    except KeyError:
        print("{0} cannot be found as a StructName in {1}".format(args.item, args.rootfolder))
        retval = "0.00"
    return (retval)


## / end get_fsvolume() function


##-- Retrieve data from FreeSurfer stats file
def get_fsdata(statsfile):
    mydict = {}
    if os.path.isfile(subjectroot + neededfiles[statsfile]):
        # Each stats file has two sections with data, a head section and
        # a body section. We need to check and mine both.
        reg_measurehead = re.compile(
            r'^#\s+Measure\s+[\w_\-]+,\s+(?P<Name>[\w_\-]+),.+?(?P<Volume>[\d\.]+),\s(?P<Dim>.+)$')
        reg_measurebody = re.compile(r'^\s*\d+\s+\d+\s+\d+\s+(?P<Volume>[\d\.]+)\s+(?P<Name>[\w_\-]+).+')
        reg_measurecort = re.compile(r'^(?P<Name>[\w_\-]+)\s+\d+\s+\d+\s+(?P<Volume>[\d\.]+).+')
        f = open(subjectroot + neededfiles[statsfile])
        for line in f:
            linetype = ""
            mat_measurehead = reg_measurehead.match(line)
            mat_measurebody = reg_measurebody.match(line)
            mat_measurecort = reg_measurecort.match(line)
            if mat_measurehead:
                linetype = "HEAD"
                # print("HEAD: {Name}={Volume}".format(Name=mat_measurehead.group('Name'), Volume=mat_measurehead.group('Volume')))
                mydict[mat_measurehead.group('Name')] = mat_measurehead.group('Volume')
            if mat_measurebody:
                linetype = "BODY"
                # print("BODY: {Name}={Volume}".format(Name=mat_measurebody.group('Name'), Volume=mat_measurebody.group('Volume')))
                mydict[mat_measurebody.group('Name')] = mat_measurebody.group('Volume')
            if mat_measurecort:
                linetype = "CORT"
                # print("CORT: {Name}={Volume}".format(Name=mat_measurecort.group('Name'), Volume=mat_measurecort.group('Volume')))
                mydict[mat_measurecort.group('Name')] = mat_measurecort.group('Volume')
            #			if linetype == "":
            #				print("No match for \"{0}\"".format(line))
        f.close()
    return (mydict)


##-- Write fields and values to csv file
def outputcsv(mynames, myvalues, myfile):
    file_is_new = not os.path.isfile(myfile)
    with open(myfile, 'a') as csvfile:
        mywriter = csv.writer(csvfile, delimiter=",", quotechar="\"", quoting=csv.QUOTE_MINIMAL)
        if file_is_new:
            mywriter.writerow(mynames)
        mywriter.writerow(myvalues)


##-- Save out the freesurfer data in tabular format for a single fs file
def write_fsfile(outfilename, fstype):
    myname = outfilename[:-4] + '.' + fstype + outfilename[-4:]
    rowNames = []
    rowData = []
    for n, d in get_metadict(subjectid, get_fstime("short", "end")).items():
        rowNames.append(n)
        rowData.append(d)

    if fstype == 'aseg':
        mydata = get_fsdata(fstype)
    elif fstype == 'wmparc':
        mydata = get_fsdata(fstype)
    elif fstype == 'aparc':
        mydata = OrderedDict([(k + '_L', v) for k, v in get_fsdata('aparc1l').items()])
        mydata.update(OrderedDict([(k + '_R', v) for k, v in get_fsdata('aparc1r').items()]))

    for n, d in mydata.items():
        rowNames.append(n)
        rowData.append(d)

    print("Writing raw {ft} data for {sid} to {fp}".format(ft=fstype, sid=subjectid, fp=myname))
    outputcsv(rowNames, rowData, myname)


##-- Order the variables and their labels for an mrs-formatted file
def write_mrsfile(wholedict, csvmrsfile):
    rowNames = []
    rowData = []
    for n, d in get_mrsmeta_dict(subjectid, get_fstime("short", "end")).items():
        rowNames.append(n)
        rowData.append(d)
    for n, d in get_mrs_dict().items():
        # each key-value pair looks like 'mrs#':'Name'
        # append the identifier (key) to the beginning of the mrs list
        rowNames.append(n)
        # and find the appropriate data value to match it
        if wholedict.get(d, "FAIL") != "FAIL":
            # Successful lookup of mrs number from FreeSurfer description
            rowData.append(wholedict.get(d, "FAIL"))
        else:
            if d == "ThalamusProper_T":
                # This exception is necessary to match the tweaked mrs variable names
                lval = float(wholedict.get('Left-Thalamus-Proper', "0.0"))  # Match at Left-***
                rval = float(wholedict.get('Right-Thalamus-Proper', "0.0"))  # Match at Right-***
                rowData.append("{:0.2f}".format(lval + rval))
            elif d == "Vetrical_T":
                # This exception adds up all ventricles and stores them under the mrs mis-spelling
                ventricles = (float(wholedict.get('Left-Lateral-Ventricle', "0.0")) +
                              float(wholedict.get('Left-Inf-Lat-Vent', "0.0")) +
                              float(wholedict.get('3rd-Ventricle', "0.0")) +
                              float(wholedict.get('4th-Ventricle', "0.0")) +
                              float(wholedict.get('Right-Lateral-Ventricle', "0.0")) +
                              float(wholedict.get('Right-Inf-Lat-Vent', "0.0")) +
                              float(wholedict.get('5th-Ventricle', "0.0")))
                rowData.append("{:0.2f}".format(ventricles))
            elif d[-2:] == "_T":
                # We have a "total" field, so we need to find the left and right fields to add for it
                if wholedict.get(d[:-2] + '_L', "FAIL") == "FAIL":
                    if wholedict.get('Left-' + d[:-2], "FAIL") == "FAIL":
                        print(
                            "--== ERROR: {4}-{0}: {1} but no {2} or {3}. Setting it to 0.0".format(n, d, d[:-2] + '_L',
                                                                                                   'Left-' + d[:-2],
                                                                                                   subjectid))
                        lval = 0.0  # No match, actual failure
                    else:
                        lval = float(wholedict.get('Left-' + d[:-2], "0.0"))  # Match at Left-***
                else:
                    lval = float(wholedict.get(d[:-2] + '_L', "0.0"))  # Match at ***_L
                if wholedict.get(d[:-2] + '_R', "FAIL") == "FAIL":
                    if wholedict.get('Right-' + d[:-2], "FAIL") == "FAIL":
                        print(
                            "--== ERROR: {4}-{0}: {1} but no {2} or {3}. Setting it to 0.0".format(n, d, d[:-2] + '_R',
                                                                                                   'Right-' + d[:-2],
                                                                                                   subjectid))
                        rval = 0.0  # No match, actual failure
                    else:
                        rval = float(wholedict.get('Right-' + d[:-2], "0.0"))  # Match at Right-***
                else:
                    rval = float(wholedict.get(d[:-2] + '_R', "0.0"))  # Match at ***_R
                rowData.append("{:0.2f}".format(lval + rval))
            else:
                rowData.append("0.00")
    print("Writing standard mrs data for {sid} to {fp}".format(sid=subjectid, fp=csvmrsfile))
    outputcsv(rowNames, rowData, csvmrsfile)


##------------------------------------------------------------------------------
##-- Define expected command-line arguments
##------------------------------------------------------------------------------


##-- Parse command-line arguments
argparser = argparse.ArgumentParser(description='Dig for information from FreeSurfer output')
argparser.add_argument('rootfolder', help='Provide a subject\'s root FreeSurfer output folder.')
argparser.add_argument('-s', '--sparse', action='store_true', help='Avoid printing the ID, keep it sparse.')
argparser.add_argument('-v', '--version_short', action='store_true', help='Output the dot version of FreeSurfer used.')
argparser.add_argument('-V', '--version_long', action='store_true', help='Output the full version of FreeSurfer used.')
argparser.add_argument('-t', '--time_short', action='store_true', help='Output the total elapsed time of the whole run.')
argparser.add_argument('-T', '--time_long', action='store_true', help='Output the individual timings of each step.')
argparser.add_argument('-u', '--username', action='store_true', help='Output the user account running freesurfer.')
argparser.add_argument('-m', '--machine', action='store_true', help='Output the host on which this subject was run.')
argparser.add_argument('-c', '--completion', action='store_true', help='Output success or failure of the job.')
argparser.add_argument('-d', '--completedate', action='store_true', help='Output the date FreeSurfer completed its processing.')
argparser.add_argument('-D', '--scandate', action='store_true', help='Only works for GENOA naming of files, return date of MRI.')
argparser.add_argument('-i', '--item', help='Output the item specified, looked up by FreeSurfer StructName.')
argparser.add_argument('--mrsfile', help='Generate an ARIC-style MRS document to the csv file specified.')
argparser.add_argument('--plus', action='store_true',
                       help='If mrsfile is also specified, put ALL available data into it, with FreeSurfer names, not mrs.')
args = argparser.parse_args()

subjectroot = os.path.abspath(args.rootfolder)

##-- Do we have a legitimate set of freesurfer data to work with?
if not input_ok(subjectroot):
    sys.exit()

##------------------------------------------------------------------------------
##-- Finally, with functions and arguments ready, do our thing...
##------------------------------------------------------------------------------


##-- Start by determining the subject ID
reg_id = re.compile(r'.*(?P<sid>[A-Za-z][0-9]{6})')
mat_id = reg_id.match(subjectroot)
if mat_id:
    subjectid = mat_id.group('sid')
else:
    print("I can't determine a subject's ID from '{}'.".format(subjectroot))
    sys.exit()

##-- Deal with versioning
if args.version_short:
    if args.sparse:
        print(get_fsversion(verbosity="short", sparsity=args.sparse))
    else:
        print("{sid} : {ver}".format(sid=subjectid, ver=get_fsversion(verbosity="short", sparsity=args.sparse)))
elif args.version_long:
    if args.sparse:
        print(get_fsversion(verbosity="long", sparsity=args.sparse))
    else:
        print("{sid} : {ver}".format(sid=subjectid, ver=get_fsversion(verbosity="long", sparsity=args.sparse)))

##-- Deal with elapsed times
if args.time_short:
    if args.sparse:
        print(get_fstime(verbosity="short", timetype="elapsed", sparsity=args.sparse))
    else:
        print("{sid} : {elapsed}".format(sid=subjectid, elapsed=get_fstime(verbosity="short", timetype="elapsed", sparsity=args.sparse)))
elif args.time_long:
    if args.sparse:
        print(get_fstime(verbosity="long", timetype="elapsed", sparsity=args.sparse))
    else:
        print("{sid} : {elapsed}".format(sid=subjectid, elapsed=get_fstime(verbosity="long", timetype="elapsed", sparsity=args.sparse)))

##-- Determine the completion status
if args.completion:
    if os.path.isfile(subjectroot + optionfiles["err"]):
        if args.sparse:
            print("error   ")
        else:
            f = open(subjectroot + optionfiles["err"])
            lastline = ""
            for line in f:
                lastline = line
            f.close()
            print("{} : Error in '{}'".format(subjectid, lastline))
    if os.path.isfile(subjectroot + optionfiles["done"]):
        if args.sparse:
            print("complete")
        else:
            print("{} : complete".format(subjectid))

##-- Determine the user or hostname
if args.username:
    if args.sparse:
        print(get_fsusername("short", args.sparse))
    else:
        print("{sid} : {username}".format(sid=subjectid, username=get_fsusername("short", args.sparse)))

##-- Determine the machine name that ran FreeSurfer
if args.machine:
    if args.sparse:
        print(get_fshostname("short", args.sparse))
    else:
        print("{sid} : {hostname}".format(sid=subjectid, hostname=get_fshostname("short", args.sparse)))

##-- Determine the date FreeSurfer completed
if args.completedate:
    if args.sparse:
        print(get_fstime(timetype='end', sparsity=args.sparse))
    else:
        print("{sid} : {d}".format(sid=subjectid, d=get_fstime(timetype='end', sparsity=args.sparse)))

##-- Determine the date the MRI was done
if args.scandate:
    if args.sparse:
        print(get_scandate(args.sparse))
    else:
        print("{sid} : {d}".format(sid=subjectid, d=get_scandate(args.sparse)))

##-- Look up item in FreeSurfer files
if args.item:
    if args.sparse:
        print(get_fsvolume(whichnum=args.item, sparsity=args.sparse))
    else:
        print("{sid} : {structname} = {structvalue}".format(sid=subjectid, structname=args.item, structvalue=get_fsvolume(whichnum=args.item, sparsity=args.sparse)))

##-- Generate whole csv with bunches of data
if args.mrsfile:
    # Merge dictionaries
    dict_whole = get_fsdata('aseg')
    dict_whole.update(get_fsdata('wmparc'))
    dict_whole.update(OrderedDict([(k + '_L', v) for k, v in get_fsdata('aparc1l').items()]))
    dict_whole.update(OrderedDict([(k + '_R', v) for k, v in get_fsdata('aparc1r').items()]))

    if args.plus:
        write_fsfile(args.mrsfile, 'aseg')
        write_fsfile(args.mrsfile, 'wmparc')
        write_fsfile(args.mrsfile, 'aparc')
    else:
        write_mrsfile(dict_whole, args.mrsfile)

# print("Done!")
